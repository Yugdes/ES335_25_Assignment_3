{
  "context_length": 3,
  "embedding_dim": 32,
  "activation": "relu",
  "vocab_size": 100000,
  "hidden_size": 1024,
  "epochs": 200,
  "batch_size": 512,
  "learning_rate": 0.001,
  "final_val_loss": 26.298037413782723,
  "final_val_accuracy": 19.332841872465906
}